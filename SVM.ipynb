{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing various libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'textblob'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtextblob\u001b[39;00m \u001b[39mimport\u001b[39;00m TextBlob\n\u001b[0;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mmpl\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'textblob'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from textblob import TextBlob\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import _pickle as cPickle\n",
    "from scipy.io import loadmat\n",
    "from sklearn.svm import SVC\n",
    "import seaborn as sns\n",
    "sns.set_context('notebook')\n",
    "sns.set_style('white')\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer ,TfidfVectorizer,TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score, confusion_matrix, roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>is so sad for my APL frie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>I missed the New Moon trail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>omg its already 7:30 :O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ItemID  Sentiment                                      SentimentText\n",
       "0       1          0                       is so sad for my APL frie...\n",
       "1       2          0                     I missed the New Moon trail...\n",
       "2       3          1                            omg its already 7:30 :O"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"sample.csv\");\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is downloaded from https://www.kaggle.com/c/si650winter11/data\n",
    "this is a TSV (\"tab separated values\") file, where the first column is a label saying whether the given review\n",
    "is positive or negative. The second column is the review itself.\n",
    "Data is tab separeted and therefore \"\\t\" is passed as separator parameter to function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9989\n"
     ]
    }
   ],
   "source": [
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total no of reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">ItemID</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sentiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5807.0</td>\n",
       "      <td>4381.127260</td>\n",
       "      <td>2730.160881</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2086.50</td>\n",
       "      <td>4016.0</td>\n",
       "      <td>6436.50</td>\n",
       "      <td>10000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4182.0</td>\n",
       "      <td>5852.401243</td>\n",
       "      <td>2879.241444</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3772.25</td>\n",
       "      <td>6458.5</td>\n",
       "      <td>8239.25</td>\n",
       "      <td>9999.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ItemID                                                           \\\n",
       "            count         mean          std  min      25%     50%      75%   \n",
       "Sentiment                                                                    \n",
       "0          5807.0  4381.127260  2730.160881  1.0  2086.50  4016.0  6436.50   \n",
       "1          4182.0  5852.401243  2879.241444  3.0  3772.25  6458.5  8239.25   \n",
       "\n",
       "                    \n",
       "               max  \n",
       "Sentiment           \n",
       "0          10000.0  \n",
       "1           9999.0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('Sentiment').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens(review):\n",
    "    return TextBlob(review).words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                  [is, so, sad, for, my, APL, friend]\n",
       "1                 [I, missed, the, New, Moon, trailer]\n",
       "2                         [omg, its, already, 7:30, O]\n",
       "3    [Omgaga, Im, sooo, im, gunna, CRy, I, 've, bee...\n",
       "4        [i, think, mi, bf, is, cheating, on, me, T_T]\n",
       "Name: SentimentText, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head().SentimentText.apply(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function tokens() is created to parse data/review into words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ready', 'NN'),\n",
       " ('was', 'VBD'),\n",
       " ('not', 'RB'),\n",
       " ('a', 'DT'),\n",
       " ('good', 'JJ'),\n",
       " ('movie', 'NN')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlob(\"ready was not a good movie\").tags\n",
    "#nltk.help.upenn_tagset('JJ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".tags is inbuilt function provided by TextBlob it is used to assign part of speech tags to the words in text.\n",
    "It gives list of (word, POS) pairs.\n",
    "To check meaning of particular tag nltk.help.upenn_tagset('tagname') can be used eg. nltk.help.upenn_tagset('JJ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:/nltk_data/...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                  [is, so, sad, for, my, apl, friend]\n",
       "1                 [i, missed, the, new, moon, trailer]\n",
       "2                          [omg, it, already, 7:30, o]\n",
       "3    [omgaga, im, sooo, im, gunna, cry, i, 've, bee...\n",
       "4        [i, think, mi, bf, is, cheating, on, me, t_t]\n",
       "Name: SentimentText, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"wordnet\", \"C:/nltk_data/\")\n",
    "def to_lemmas(review):\n",
    "    wordss = TextBlob(review.lower()).words\n",
    "    # for each word, take its \"base form\" = lemma \n",
    "    return [word.lemma for word in wordss]\n",
    "\n",
    "df.SentimentText.head().apply(to_lemmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatization is one of the important satge of data preprocessing in this step words are converted to their lemma(base form). For example \"octopi\" is converted to \"octopus\". similar method is stemming.\n",
    "\n",
    "NLTK also provide very powerful lemmatizer which make use of WORDNET eg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'octopus'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lmtzr = WordNetLemmatizer()\n",
    "lmtzr.lemmatize('octopi')\n",
    "#nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting text data into vectors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17430\n"
     ]
    }
   ],
   "source": [
    "bow_transformer = CountVectorizer(analyzer=to_lemmas).fit(df['SentimentText'])\n",
    "print(len(bow_transformer.vocabulary_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sklearn offers Countvectorizer which counts the frequency of particular word in document. This assigns a unique number to every word in collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          .. Omgaga. Im sooo  im gunna CRy. I've been at this dentist since 11.. I was suposed 2 just get a crown put on (30mins)...\n"
     ]
    }
   ],
   "source": [
    "review1=df['SentimentText'][3]\n",
    "print(review1)\n",
    "#to check 3rd document/review in collection/database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 82)\t1\n",
      "  (0, 158)\t1\n",
      "  (0, 255)\t1\n",
      "  (0, 382)\t1\n",
      "  (0, 668)\t1\n",
      "  (0, 1495)\t1\n",
      "  (0, 1936)\t1\n",
      "  (0, 4041)\t1\n",
      "  (0, 4060)\t1\n",
      "  (0, 4458)\t1\n",
      "  (0, 6476)\t1\n",
      "  (0, 6889)\t1\n",
      "  (0, 7570)\t2\n",
      "  (0, 7697)\t2\n",
      "  (0, 8444)\t1\n",
      "  (0, 10978)\t1\n",
      "  (0, 10983)\t1\n",
      "  (0, 12150)\t1\n",
      "  (0, 13620)\t1\n",
      "  (0, 13927)\t1\n",
      "  (0, 14515)\t1\n",
      "  (0, 15049)\t1\n",
      "  (0, 16414)\t1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 17430)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow=bow_transformer.transform([review1])\n",
    "print(bow)\n",
    "bow.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Countvectorizer creates sparse matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.14\n"
     ]
    }
   ],
   "source": [
    "print(bow_transformer.get_feature_names_out()[372])\n",
    "#to check 372nd word in collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparse matrix shape: (9989, 17430)\n",
      "number of non-zeros: 120246\n",
      "sparsity: 12024600.00%\n"
     ]
    }
   ],
   "source": [
    "review_bow = bow_transformer.transform(df['SentimentText'])\n",
    "print( 'sparse matrix shape:', review_bow.shape)\n",
    "print('number of non-zeros:', review_bow.nnz) #learn this\n",
    "print( 'sparsity: %.2f%%' % (100.0 * review_bow.nnz))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "shape of sparse matrix n*m where n are total documents and m are total unique words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CountVectorizer just count the frequency of word in that document. But many time few words such as(the, or) occurs a lot of time in collection which really don't contribute in deciding the polarity of particular document so to nullify their effect special weighting method is to be used. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tf-idf Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tf means term-frequency while tf-idf means term-frequency times inverse document-frequency.\n",
    "\n",
    "The goal of using tf-idf instead of the just CountVectorizer in a given document is to scale down the impact of tokens that occur very frequently in a given corpus(which are less informative) than tokens which occur few times.\n",
    "\n",
    "Tf-idf(d,t)=tf(d,t)*idf(d,t);\n",
    "\n",
    "where tf(d,t) is term frequency which states how many times word/token t occur in that doucument devided by total no of words in that document.\n",
    "\n",
    "and idf(d,t)=log[n/(df(d,t))] i.e. total no of documents divided by no of documents containing that word/token t."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9989, 17430)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer =TfidfTransformer().fit(review_bow)\n",
    "review_tfidf = tfidf_transformer.transform(review_bow)\n",
    "review_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count vectorizer gives output as frequency of diiferent words in our corpus this is then passed to transform method of tf-idf_transformer.\n",
    "\n",
    "This Transform a count matrix to a normalized tf or tf-idf representation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7991 1998 7991 1998\n"
     ]
    }
   ],
   "source": [
    "text_train, text_test, liked_train, liked_test = train_test_split(df['SentimentText'], df['Sentiment'], test_size=0.2)\n",
    "print(len(text_train), len(text_test), len(text_train) , len(text_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset downloaded is then divided into training data and test data with ratio 0.8 to 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_svm = Pipeline([\n",
    "    ('bow', CountVectorizer(analyzer=to_lemmas)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('classifier', SVC()),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline sequentially apply a list of transforms and a final estimator. Intermediate steps of the pipeline must be ‘transforms’, that is, they must implement fit and transform methods. The final estimator only needs to implement fit.\n",
    "\n",
    "The purpose of the pipeline is to assemble several steps that can be cross-validated together while setting different parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline parameters to automatically explore and tune\n",
    "param_svm = [\n",
    "  {'classifier__C': [1, 10, 100, 1000], 'classifier__kernel': ['linear']},\n",
    "  {'classifier__C': [1, 10, 100, 1000], 'classifier__gamma': [0.001, 0.0001], 'classifier__kernel': ['rbf']},\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_svm = GridSearchCV(\n",
    "    pipeline_svm, #object used to fit the data\n",
    "    param_grid=param_svm, \n",
    "    refit=True,  # fit using all data, on the best detected classifier\n",
    "    n_jobs=-1,  # number of cores to use for parallelization; -1 for \"all cores\" i.e. to run on all CPUs\n",
    "    scoring='accuracy',#optimizing parameter\n",
    "    cv=StratifiedKFold(n_splits=5),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exhaustive search over specified parameter values for an estimator.\n",
    "\n",
    "CV stands for cross validations. Learning the parameters of a prediction function and testing it on the same data is a methodological mistake, it will always give 100% accuracy and therefore training and testing data must be different. Cross validation is idea of dividing training data into k folds i.e. k subset. The following procedure is followed for each of the k “folds”:\n",
    "\n",
    "A model is trained using k-1 of the folds as training data;\n",
    "\n",
    "The resulting model is validated on the remaining part of the data (i.e., it is used as a test set to compute a performance measure such as accuracy).\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%time classifier = grid_svm.fit(text_train, liked_train) # find the best combination from param_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([ 9.13037014, 11.08522954, 12.18450933, 10.59441023,  8.44368329,\n",
      "        8.01027851,  8.05471473,  8.13315444,  7.57888122,  8.13708167,\n",
      "        7.85991654,  6.84219036]), 'std_fit_time': array([0.26407811, 1.29783626, 0.34860532, 0.83409847, 0.4207121 ,\n",
      "       0.35123636, 0.29753969, 0.30256759, 0.2641206 , 0.36101811,\n",
      "       0.28899139, 0.5939673 ]), 'mean_score_time': array([1.4549139 , 1.42496543, 1.36910787, 1.21375551, 1.74703059,\n",
      "       1.81991067, 1.78848014, 1.82378883, 1.66193604, 1.83337965,\n",
      "       1.53626881, 1.28753438]), 'std_score_time': array([0.06156939, 0.08474733, 0.03126889, 0.05723953, 0.01704184,\n",
      "       0.05255064, 0.05477495, 0.06909747, 0.03155687, 0.06796363,\n",
      "       0.07315922, 0.08859057]), 'param_classifier__C': masked_array(data=[1, 10, 100, 1000, 1, 1, 10, 10, 100, 100, 1000, 1000],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_classifier__kernel': masked_array(data=['linear', 'linear', 'linear', 'linear', 'rbf', 'rbf',\n",
      "                   'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_classifier__gamma': masked_array(data=[--, --, --, --, 0.001, 0.0001, 0.001, 0.0001, 0.001,\n",
      "                   0.0001, 0.001, 0.0001],\n",
      "             mask=[ True,  True,  True,  True, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'classifier__C': 1, 'classifier__kernel': 'linear'}, {'classifier__C': 10, 'classifier__kernel': 'linear'}, {'classifier__C': 100, 'classifier__kernel': 'linear'}, {'classifier__C': 1000, 'classifier__kernel': 'linear'}, {'classifier__C': 1, 'classifier__gamma': 0.001, 'classifier__kernel': 'rbf'}, {'classifier__C': 1, 'classifier__gamma': 0.0001, 'classifier__kernel': 'rbf'}, {'classifier__C': 10, 'classifier__gamma': 0.001, 'classifier__kernel': 'rbf'}, {'classifier__C': 10, 'classifier__gamma': 0.0001, 'classifier__kernel': 'rbf'}, {'classifier__C': 100, 'classifier__gamma': 0.001, 'classifier__kernel': 'rbf'}, {'classifier__C': 100, 'classifier__gamma': 0.0001, 'classifier__kernel': 'rbf'}, {'classifier__C': 1000, 'classifier__gamma': 0.001, 'classifier__kernel': 'rbf'}, {'classifier__C': 1000, 'classifier__gamma': 0.0001, 'classifier__kernel': 'rbf'}], 'split0_test_score': array([0.78236398, 0.75797373, 0.72357724, 0.7054409 , 0.58098812,\n",
      "       0.58098812, 0.58098812, 0.58098812, 0.75797373, 0.58098812,\n",
      "       0.78424015, 0.75797373]), 'split1_test_score': array([0.78848561, 0.7640801 , 0.7290363 , 0.71401752, 0.58135169,\n",
      "       0.58135169, 0.58197747, 0.58135169, 0.76032541, 0.58197747,\n",
      "       0.77784731, 0.76095119]), 'split2_test_score': array([0.76783479, 0.7252816 , 0.70525657, 0.68710889, 0.58135169,\n",
      "       0.58135169, 0.58260325, 0.58135169, 0.75031289, 0.58260325,\n",
      "       0.75782228, 0.75093867]), 'split3_test_score': array([0.77221527, 0.7428035 , 0.71214018, 0.69774718, 0.58135169,\n",
      "       0.58135169, 0.58135169, 0.58135169, 0.73967459, 0.58135169,\n",
      "       0.76846058, 0.73967459]), 'split4_test_score': array([0.77596996, 0.74843554, 0.7146433 , 0.70150188, 0.58072591,\n",
      "       0.58072591, 0.58135169, 0.58072591, 0.74718398, 0.58135169,\n",
      "       0.76345432, 0.74780976]), 'mean_test_score': array([0.77737392, 0.7477149 , 0.71693072, 0.70116327, 0.58115382,\n",
      "       0.58115382, 0.58165444, 0.58115382, 0.75109412, 0.58165444,\n",
      "       0.77036493, 0.75146959]), 'std_test_score': array([0.00732049, 0.01342354, 0.00842839, 0.00886386, 0.00025613,\n",
      "       0.00025613, 0.0005713 , 0.00025613, 0.00746794, 0.0005713 ,\n",
      "       0.00956252, 0.00754987]), 'rank_test_score': array([ 1,  5,  6,  7, 10, 10,  8, 10,  4,  8,  2,  3])}\n"
     ]
    }
   ],
   "source": [
    "print(classifier.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.86      0.82      1163\n",
      "           1       0.78      0.69      0.73       835\n",
      "\n",
      "    accuracy                           0.79      1998\n",
      "   macro avg       0.78      0.77      0.78      1998\n",
      "weighted avg       0.79      0.79      0.78      1998\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(liked_test, classifier.predict(text_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(classifier.predict([\"the vinci code is awesome\"])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(classifier.predict([\"the vinci code is bad\"])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32465246735834974"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gaussKernel(x1, x2, sigma):\n",
    "    ss=np.power(sigma,2)\n",
    "    norm= (x1-x2).T.dot(x1-x2)\n",
    "    return np.exp(-norm/(2*ss))\n",
    "x1 = np.array([1, 2, 1])\n",
    "x2 = np.array([0, 4, -1])\n",
    "sigma = 2\n",
    "gaussKernel(x1,x2,sigma)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "f6246b25e200e4c5124e3e61789ac81350562f0761bbcf92ad9e48654207659c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
